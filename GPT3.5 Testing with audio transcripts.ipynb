{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te0lf7wM84b7",
        "outputId": "bdc7d456-f88e-4e5f-af18-1f2d4aa7e3fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.5 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f05IucdS3aDy",
        "outputId": "9c5cdf5e-6a90-4c1d-b210-654df3d157ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-27 19:05:20--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v1.1.json\n",
            "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.110.153, 185.199.111.153, 185.199.109.153, ...\n",
            "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.110.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4854279 (4.6M) [application/json]\n",
            "Saving to: ‘dev-v1.1.json’\n",
            "\n",
            "dev-v1.1.json       100%[===================>]   4.63M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-04-27 19:05:21 (104 MB/s) - ‘dev-v1.1.json’ saved [4854279/4854279]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open(\"dev-v1.1.json\", \"r\") as file:\n",
        "    validation_data = json.load(file)[\"data\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "KgtGxVLn3dml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data[0][\"title\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "SujOZqQeE1-S",
        "outputId": "dc707886-5869-4404-9e38-b641675d1623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Super_Bowl_50'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data[0][\"paragraphs\"][0][\"context\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "o62jssT3FB8O",
        "outputId": "4f26fa50-0f82-4399-adb6-82fc89bb642a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi\\'s Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data[0][\"paragraphs\"][0][\"qas\"][0][\"question\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "GF-PDsQMFdXj",
        "outputId": "bde57fda-37d6-4375-dd7b-1f36b9535e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Which NFL team represented the AFC at Super Bowl 50?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 386
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data[0][\"paragraphs\"][0][\"qas\"][0][\"answers\"][0][\"text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "z5VlmgKsFxlJ",
        "outputId": "4e2d8270-de0e-4a3d-ffea-d8f26594d0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Denver Broncos'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 387
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(f\"Number of validation examples: {len(validation_data)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRjP0LDp5cz-",
        "outputId": "bb137fb1-bf2d-4b96-86ff-b0aafdf3c7b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of validation examples: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, the question is \"Which NFL team represented the AFC at Super Bowl 50?\". The context passage provides the information that the Denver Broncos were the AFC champions who played in Super Bowl 50. The answer \"Denver Broncos\" can be found within the context, starting at character index 177."
      ],
      "metadata": {
        "id": "LjVOm9s_4XT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ghcaz2i1kfk"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "# load and set our key\n",
        "openai.api_key = 'paste your API key here'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, accuracy_score"
      ],
      "metadata": {
        "id": "Ko7MY_ej9sA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"gpt-3.5-turbo\" # \"gpt-3.5-turbo\" or \"gpt-4\".\n",
        "max_num_questions = 10"
      ],
      "metadata": {
        "id": "3jH9aiYXXCpZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function facilitates a conversation with the ChatGPT model by maintaining a conversation log and sending it to the model for generating responses. The conversation continues until the model reaches a stopping point.\n",
        "\n",
        "Args:\n",
        "conversation_log (list): A list of dictionaries containing the conversation history, where each dictionary has 'role' and 'content' keys.\n",
        "model_id (str): The identifier for the ChatGPT model to be used for generating responses: \"gpt-3.5-turbo\" or \"gpt-4\".\n",
        "\n",
        "Returns:\n",
        "list: An updated conversation log that includes the model's responses.\n",
        "\n",
        "Example:\n",
        "conversation_log = [{'role': 'user', 'content': 'tell me a joke'}]\n",
        "model_id = 'gpt-4'\n",
        "updated_conversation_log = chatgpt_conversation(conversation_log, model_id)\n",
        "\"\"\"\n",
        "def chatgpt_conversation(conversation_log, model_id):\n",
        "  # Generate an initial response from the ChatGPT model based on the conversation log\n",
        "  response = openai.ChatCompletion.create(\n",
        "        model=model_id,\n",
        "        messages=conversation_log \n",
        "  )\n",
        "  # Extract role and content from the response\n",
        "  role = response.choices[0].message.role.strip()\n",
        "  content = response.choices[0].message.content.strip()\n",
        "  # Add the response to the conversation log\n",
        "  conversation_log.append({'role': role, 'content': content})\n",
        "  print('{0}: {1}\\n'.format(role, content))\n",
        "  # Create a copy of the conversation log\n",
        "  conversation_log_copy = conversation_log.copy()\n",
        "  # Continue the conversation until the model reaches a stopping point\n",
        "  while (response.choices[0].finish_reason != 'stop'):\n",
        "    # Add a 'continue' message to the conversation log copy\n",
        "    conversation_log_copy.append({'role': 'user', \n",
        "                                  'content': 'continue'})\n",
        "    # Generate a response from the ChatGPT model based on the updated conversation log copy\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model_id,\n",
        "        messages=conversation_log_copy\n",
        "    )\n",
        "    # Extract role and content from the response\n",
        "    role = response.choices[0].message.role.strip()\n",
        "    content = response.choices[0].message.content.strip()\n",
        "    # Add the response to the conversation log and conversation log copy\n",
        "    reply = {'role': role, 'content': content}\n",
        "    conversation_log.append(reply)\n",
        "    conversation_log_copy.append(reply)\n",
        "    print('{0} (continued): {1}\\n'.format(role, content))\n",
        "  return conversation_log\n",
        "  "
      ],
      "metadata": {
        "id": "aqhnXvB6A370"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_template = \"Context: [<a passage from the Wikipedia article that contains the answer to the question>].\\n Questions: 1) [<first question>]; 2) [<second question>], 3) [<third question>].\"\n",
        "reply_template = \"Question1: [<repeat the first question here>];\\n Reply1: [<a reply to the question 1, given by a substring from Context>];\\n Question2: [<repeat the second question here>];\\n Reply2: [<a reply to the question 2, given by a substring from Context>];\\n Question3: [<repeat the third question here>];\\n Reply3: [<a reply to the question 3, given by a substring from Context>].\""
      ],
      "metadata": {
        "id": "Wv0DbnmbX4w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_example = \"\"\" Context: [Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24–10 to earn their third Super Bowl title. The game was played on February 7, 2016, at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals 50.].\n",
        " Questions: 1) [Which NFL team represented the AFC at Super Bowl 50?]; 2) [Which NFL team represented the NFC at Super Bowl 50?]; 3) [Where did Super Bowl 50 take place?]; 4) [Which NFL team won Super Bowl 50?]; 5) [What color was used to emphasize the 50th anniversary of the Super Bowl?]; 6) [What was the theme of Super Bowl 50?]; 7) [What day was the game played on?]; 8) [What is the AFC short for?]; 9) [What was the theme of Super Bowl 50?]; 10) [What does AFC stand for?].\n",
        "Remember: All answers must be exact substrings from the 'Context' string. Do not paraphrase or modify the answers. Keep your answers concise, typically containing a single number, date, name, etc. Don't use punctuation marks at the end of the answer. Provide longer answers with more than 3 words only when necessary.\"\"\"\n",
        "reply_example = \"\"\"Question1: [Which NFL team represented the AFC at Super Bowl 50?];\n",
        " Reply1: [Denver Broncos];\n",
        " Question2: [Which NFL team represented the NFC at Super Bowl 50?];\n",
        " Reply2: [Carolina Panthers];\n",
        " Question3: [Where did Super Bowl 50 take place?];\n",
        " Reply3: [Santa Clara, California];\n",
        " Question4: [Which NFL team won Super Bowl 50?];\n",
        " Reply4: [Denver Broncos];\n",
        " Question5: [What color was used to emphasize the 50th anniversary of the Super Bowl?];\n",
        " Reply5: [gold];\n",
        " Question6: [What was the theme of Super Bowl 50?];\n",
        " Reply6: [\"golden anniversary\"];\n",
        " Question7: [What day was the game played on?];\n",
        " Reply7: [February 7, 2016];\n",
        " Question8: [What is the AFC short for?];\n",
        " Reply8: [American Football Conference];\n",
        " Question9: [What was the theme of Super Bowl 50?];\n",
        " Reply9: [\"golden anniversary\"];\n",
        " Question10: [What does AFC stand for?];\n",
        " Reply10: [American Football Conference].\"\"\""
      ],
      "metadata": {
        "id": "c9wtADzQ82zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a system message, which sets the behavior of the assistant. \n",
        "conversations = []\n",
        "intro = f\"\"\"You are ChatGPT, a large language model trained by OpenAI. A user wants to evaluate your performance on a question answering dataset by comparing your replies to reference answers, using the EM and F1 scores.\n",
        "Your task is to answer questions based on the provided context. All answers should be exact substrings from the \\\"Context\\\" string. However, the user is using audio transcripts, which means that some context data might be lost. You will have to \"recover\" this information or infer it from the context using your understanding of the content. Do not paraphrase or modify the answers unless you are trying to recover lost data.\n",
        "The user will ask up to {max_num_questions} questions at a time, formatted as follows: \\\"{question_template}\\\". \n",
        "Keep your answers concise, typically containing a single number, date, name, etc. Provide longer answers of more than 3 words only when necessary.\n",
        "Your reply should be formatted as follows: \\\"{reply_template}\\\". Focus on answering questions accurately and following the reply format to ensure the best performance.\n",
        "I'm providing the example of the user message that asks 10 questions based on the context and an example of the perfect answer you should ideally give. \n",
        "\n",
        "If the user message is as follows: \\\"{question_example}\\\", then your reply must be as follows: \\\"{reply_example}\\\".\n",
        "Do you understand a task?\"\"\"\n",
        "reminder = \"Remember: All answers must be exact substrings from the 'Context' string. Do not paraphrase or modify the answers. Keep your answers concise, typically containing a single number, date, name, etc. Don't use punctuation marks at the end of the answer. Provide longer answers with more than 3 words only when necessary.\"\n",
        "# Roles: system, user, assistant\n",
        "conversations.append({'role': 'system', 'content': intro})\n"
      ],
      "metadata": {
        "id": "-HjWQ2jcPTIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feed a system message.\n",
        "conversations = chatgpt_conversation(conversations, model_id)\n",
        "init_conversation = conversations.copy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5g5CfjSXP3zS",
        "outputId": "adea361b-f8a3-4699-fa95-92b95b9faf8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: Yes, I understand the task.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function creates a formatted user message string by combining context, questions, and a reminder.\n",
        "The message is printed and returned.\n",
        "\n",
        "Args:\n",
        "context (str): A string describing the context.\n",
        "questions (list): A list of strings containing the questions to be included in the user message.\n",
        "reminder (str): A string containing a reminder to be appended to the user message.\n",
        "\n",
        "Returns:\n",
        "str: A formatted user message string.\n",
        "\"\"\"\n",
        "def create_user_msg(context, questions, reminder):\n",
        "  user_msg = f\"Context: [{context}].\\n Questions: \"\n",
        "  # Iterate through the list of questions and append them to the user message\n",
        "  for i in range(len(questions)):\n",
        "    user_msg += f\"{i+1}) [{questions[i]}]\"\n",
        "    # Add a semicolon separator for all questions except the last one\n",
        "    if (i+1 != len(questions)):\n",
        "      user_msg += \"; \"\n",
        "  # Close the questions section and add a period\n",
        "  user_msg += \".\\n\"\n",
        "  # Append the reminder to the user message\n",
        "  user_msg += reminder\n",
        "  print(user_msg)\n",
        "  return user_msg"
      ],
      "metadata": {
        "id": "rgzzjdTorai7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\"\"\"\n",
        "This function generates replies to a list of questions in a given context using the ChatGPT model.\n",
        "It first creates a user message that combines the context, questions, and a reminder, and then\n",
        "interacts with the ChatGPT model to obtain replies.\n",
        "\n",
        "Args:\n",
        "context (str): A string describing the context of the questions.\n",
        "questions (list): A list of strings containing the questions to be answered.\n",
        "conversations (list): A list of dictionaries containing the conversation history with ChatGPT.\n",
        "reminder (str): A string containing a reminder to be appended to the user message.\n",
        "model_id (str): The identifier for the ChatGPT model to be used for generating responses: \"gpt-3.5-turbo\" or \"gpt-4\".\n",
        "\n",
        "Returns:\n",
        "list: A list of strings containing the replies generated by the ChatGPT model.\n",
        "\"\"\"\n",
        "def get_replies(context, questions, conversations, reminder, model_id):\n",
        "    replies = []\n",
        "    # Send a request to chatGPT with the created user message\n",
        "    conversations.append({'role': 'user', \n",
        "                          'content': create_user_msg(context, questions, reminder)})\n",
        "    conversations = chatgpt_conversation(conversations, model_id)\n",
        "    # Extract the content of the latest response from ChatGPT\n",
        "    answer = conversations[-1]['content']\n",
        "\n",
        "    # Extract replies using a regular expression\n",
        "    reply_pattern = re.compile(r\"Reply\\d+: \\[(.*?)\\]\")\n",
        "    extracted_replies = reply_pattern.findall(answer)\n",
        "    # Append each extracted reply to the replies list\n",
        "    for extracted_reply in extracted_replies:\n",
        "        replies.append(extracted_reply)\n",
        "\n",
        "    return replies\n"
      ],
      "metadata": {
        "id": "5XHaLmNboKtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\"\"\"\n",
        "This function retrieves a transcript from a combined DataFrame based on the specified article index and paragraph index. It returns the corresponding transcript if it exists.\n",
        "\n",
        "Args:\n",
        "combined_df (pd.DataFrame): A pandas DataFrame containing the combined data, including article index, paragraph index, and transcriptions.\n",
        "article_idx (int): The index of the target article in the combined_df.\n",
        "paragraph_idx (int): The index of the target paragraph in the combined_df.\n",
        "\n",
        "Returns:\n",
        "str: The corresponding transcript if it exists, or None if no transcription is found.\n",
        "\"\"\"\n",
        "def get_transcript(combined_df, article_idx, paragraph_idx):\n",
        "  # Query the combined DataFrame for the specified article_idx and paragraph_idx\n",
        "    result = combined_df.query(f'article_idx == {article_idx} and paragraph_idx == {paragraph_idx}')\n",
        "\n",
        "    if not result.empty:\n",
        "        # Retrieve the transcription from the result\n",
        "        transcription = result['transcription'].iloc[0]\n",
        "        return transcription\n",
        "    else:\n",
        "        print('ERROR: No transcription found for the specified article_idx and paragraph_idx.')"
      ],
      "metadata": {
        "id": "NQfruCwBckI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function writes replies generated by the ChatGPT model to a set of questions\n",
        "from multiple paragraphs of an article. It takes an initial conversation, validation_data,\n",
        "and other parameters to control the extraction of replies and stores the generated replies as a JSON file.\n",
        "\n",
        "Args:\n",
        "init_conversation (list): A list of dictionaries containing the initial conversation history with ChatGPT, which includes a system message with instructions.\n",
        "validation_data (list): A list of dictionaries containing article data, including paragraphs and questions.\n",
        "art_idx (int): The index of the target article in the validation_data.\n",
        "start_par_idx (int): The starting index of the paragraphs to process.\n",
        "num_paragraphs (int): The number of paragraphs to process.\n",
        "max_num_questions (int): The maximum number of questions to process at once.\n",
        "model_id (str): The identifier for the ChatGPT model to be used for generating responses.\n",
        "tran_df (pd.DataFrame): A pandas DataFrame containing the combined data, including article index, paragraph index, and transcriptions.\n",
        "\"\"\"\n",
        "def write_replies_with_transcripts(init_conversation, validation_data, art_idx, start_par_idx, num_paragraphs, max_num_questions, model_id, tran_df):\n",
        "  article = validation_data[art_idx]\n",
        "  art_replies = []\n",
        "  paragraphs = article[\"paragraphs\"]\n",
        "  # Iterate over all paragraphs in an article\n",
        "  for par_idx in range(start_par_idx, min(start_par_idx + num_paragraphs, len(paragraphs))):\n",
        "    paragraph = paragraphs[par_idx]\n",
        "    par_replies = []\n",
        "    context = get_transcript(tran_df, art_idx, par_idx)\n",
        "    # context = paragraph[\"context\"] # You just have to substitute context here with the transcript \n",
        "    questions = []\n",
        "    conversations = init_conversation.copy()\n",
        "    for qs_idx in range(len(paragraph[\"qas\"])):\n",
        "      if (len(questions) == max_num_questions):\n",
        "        par_replies.extend(get_replies(context, questions, conversations, reminder, model_id))\n",
        "        # Clear questions.\n",
        "        questions = []\n",
        "      questions.append(paragraph[\"qas\"][qs_idx][\"question\"])\n",
        "    if (len(questions) != 0):\n",
        "      par_replies.extend(get_replies(context, questions, conversations, reminder,  model_id))\n",
        "    art_replies.append(par_replies)\n",
        "  if (len(art_replies) != 0):\n",
        "    # Write the rest of the replies.\n",
        "    # Modify this line to save files all to a tmp json!\n",
        "     with open(f\"/content/jsons_tmp2/{art_idx}_{start_par_idx}.json\", \"w\") as file:\n",
        "        json.dump(art_replies, file)\n"
      ],
      "metadata": {
        "id": "YeYbrXoj3lh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This function initiates the process of writing replies generated by the ChatGPT model\n",
        "for multiple articles within a specified range. It takes an initial conversation, validation_data,\n",
        "and other parameters to control the extraction of replies and calls the write_replies function to\n",
        "store the generated replies as JSON files.\n",
        "\n",
        "Args:\n",
        "init_conversation (list): A list of dictionaries containing the initial conversation history with ChatGPT.\n",
        "validation_data (list): A list of dictionaries containing article data, including paragraphs and questions.\n",
        "start_art_idx (int): The starting index of the articles to process.\n",
        "end_art_idx (int): The ending index of the articles to process.\n",
        "start_par_idx (int): The starting index of the paragraphs to process.\n",
        "num_paragraphs (int): The number of paragraphs to process at once.\n",
        "max_num_questions (int): The maximum number of questions to process at once.\n",
        "model_id (str): The identifier for the ChatGPT model to be used for generating responses.\n",
        "tran_df (pd.DataFrame): A pandas DataFrame containing the combined data, including article index, paragraph index, and transcriptions.\n",
        "\"\"\"\n",
        "def start_writing_replies_with_tran(init_conversation, validation_data, start_art_idx, end_art_idx, start_par_idx, num_paragraphs, max_num_questions, model_id, tran_df):\n",
        "  for art_idx in range(start_art_idx, end_art_idx + 1):\n",
        "    article = validation_data[art_idx]\n",
        "    paragraphs = article[\"paragraphs\"]\n",
        "    while (start_par_idx < len(paragraphs)):\n",
        "      write_replies_with_transcripts(init_conversation, validation_data, art_idx, start_par_idx, num_paragraphs, max_num_questions, model_id, tran_df)\n",
        "      start_par_idx += num_paragraphs\n",
        "    start_par_idx = 0"
      ],
      "metadata": {
        "id": "0zdiT4bBc6Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_art_idx = 1\n",
        "end_art_idx = 5\n",
        "start_par_idx = 0\n",
        "num_paragraphs = 5\n",
        "tran_df_4khz = pd.read_csv(\"/content/dev_1_4khz_1_transcripts_wer.csv\")\n",
        "start_writing_replies_with_tran(init_conversation, validation_data, start_art_idx, end_art_idx, start_par_idx, num_paragraphs, max_num_questions, model_id, tran_df_4khz)\n"
      ],
      "metadata": {
        "id": "4pJ4QqLudQA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all json files into a single file.\n",
        "replies_output = []\n",
        "num_paragraphs = 5\n",
        "for art_idx in range(1, 6):\n",
        "  article = validation_data[art_idx]\n",
        "  paragraphs = article[\"paragraphs\"]\n",
        "  start_par_idx = 0\n",
        "  art_replies = []\n",
        "  while (start_par_idx < len(paragraphs)):\n",
        "    with open(f\"/content/jsons_tmp2/{art_idx}_{start_par_idx}.json\", \"r\") as file:\n",
        "      art_replies.extend(json.load(file))\n",
        "    start_par_idx += num_paragraphs\n",
        "  \n",
        "  replies_output.append(art_replies)"
      ],
      "metadata": {
        "id": "l-sEeC3_dsaf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the JSON array to a file\n",
        "with open(\"gpt4_replies_with_4khz_context.json\", \"w\") as file:\n",
        "    json.dump(replies_output, file)"
      ],
      "metadata": {
        "id": "wrjkp7tXdva2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}